<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=edge"/>
<title>Test results - CdcPostgresSourceTest</title>
<link href="../css/base-style.css" rel="stylesheet" type="text/css"/>
<link href="../css/style.css" rel="stylesheet" type="text/css"/>
<script src="../js/report.js" type="text/javascript"></script>
</head>
<body>
<div id="content">
<h1>CdcPostgresSourceTest</h1>
<div class="breadcrumbs">
<a href="../index.html">all</a> &gt; 
<a href="../packages/io.airbyte.integrations.source.postgres.html">io.airbyte.integrations.source.postgres</a> &gt; CdcPostgresSourceTest</div>
<div id="summary">
<table>
<tr>
<td>
<div class="summaryGroup">
<table>
<tr>
<td>
<div class="infoBox" id="tests">
<div class="counter">22</div>
<p>tests</p>
</div>
</td>
<td>
<div class="infoBox" id="failures">
<div class="counter">0</div>
<p>failures</p>
</div>
</td>
<td>
<div class="infoBox" id="ignored">
<div class="counter">0</div>
<p>ignored</p>
</div>
</td>
<td>
<div class="infoBox" id="duration">
<div class="counter">34m39.20s</div>
<p>duration</p>
</div>
</td>
</tr>
</table>
</div>
</td>
<td>
<div class="infoBox success" id="successRate">
<div class="percent">100%</div>
<p>successful</p>
</div>
</td>
</tr>
</table>
</div>
<div id="tabs">
<ul class="tabLinks">
<li>
<a href="#tab0">Tests</a>
</li>
<li>
<a href="#tab1">Standard output</a>
</li>
</ul>
<div id="tab0" class="tab">
<h2>Tests</h2>
<table>
<thead>
<tr>
<th>Test</th>
<th>Method name</th>
<th>Duration</th>
<th>Result</th>
</tr>
</thead>
<tr>
<td class="success">newTableSnapshotTest()</td>
<td class="success">newTableSnapshotTest()</td>
<td class="success">1m47.27s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">syncShouldHandlePurgedLogsGracefully()</td>
<td class="success">syncShouldHandlePurgedLogsGracefully()</td>
<td class="success">51.177s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">syncShouldIncrementLSN()</td>
<td class="success">syncShouldIncrementLSN()</td>
<td class="success">1m24.50s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">When both incremental CDC and full refresh are configured for different streams in a sync, the data is replicated as expected.</td>
<td class="success">testCdcAndFullRefreshInSameSync()</td>
<td class="success">42.030s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testCheck()</td>
<td class="success">testCheck()</td>
<td class="success">9.587s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testCheckReplicationAccessReplicationPrivilege()</td>
<td class="success">testCheckReplicationAccessReplicationPrivilege()</td>
<td class="success">8.435s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testCheckReplicationAccessSuperUserPrivilege()</td>
<td class="success">testCheckReplicationAccessSuperUserPrivilege()</td>
<td class="success">10.300s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testCheckWithoutPublication()</td>
<td class="success">testCheckWithoutPublication()</td>
<td class="success">9.876s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testCheckWithoutReplicationPermission()</td>
<td class="success">testCheckWithoutReplicationPermission()</td>
<td class="success">8.278s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testCheckWithoutReplicationSlot()</td>
<td class="success">testCheckWithoutReplicationSlot()</td>
<td class="success">8.901s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">When a record is deleted, produces a deletion record.</td>
<td class="success">testDelete()</td>
<td class="success">42.086s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testDiscover()</td>
<td class="success">testDiscover()</td>
<td class="success">9.764s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testDiscoverFiltersNonPublication()</td>
<td class="success">testDiscoverFiltersNonPublication()</td>
<td class="success">10.432s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">On the first sync, produce returns records that exist in the database.</td>
<td class="success">testExistingData()</td>
<td class="success">21.014s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">When no records exist, no records are returned.</td>
<td class="success">testNoData()</td>
<td class="success">19.801s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">When no changes have been made to the database since the previous sync, no records are returned.</td>
<td class="success">testNoDataOnSecondSync()</td>
<td class="success">1m1.42s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testReachedTargetPosition()</td>
<td class="success">testReachedTargetPosition()</td>
<td class="success">19.702s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">Verify that when data is inserted into the database while a sync is happening and after the first sync, it all gets replicated.</td>
<td class="success">testRecordsProducedDuringAndAfterSync()</td>
<td class="success">1m28.01s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testTableWithTimestampColDefault()</td>
<td class="success">testTableWithTimestampColDefault()</td>
<td class="success">20.326s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">When a record is updated, produces an update record.</td>
<td class="success">testUpdate()</td>
<td class="success">41.493s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">verifyCheckpointStatesByRecords()</td>
<td class="success">verifyCheckpointStatesByRecords()</td>
<td class="success">12m59.28s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">verifyCheckpointStatesBySeconds()</td>
<td class="success">verifyCheckpointStatesBySeconds()</td>
<td class="success">10m25.52s</td>
<td class="success">passed</td>
</tr>
</table>
</div>
<div id="tab1" class="tab">
<h2>Standard output</h2>
<span class="code">
<pre>{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.u.ImageNameSubstitutor(instance):55 Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.d.DockerClientProviderStrategy(lambda$loadConfiguredStrategy$9):362 Loaded org.testcontainers.dockerclient.UnixSocketClientProviderStrategy from ~/.testcontainers.properties, will try it first&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.d.DockerClientProviderStrategy(tryOutStrategy):272 Found Docker environment with local Unix socket (unix:///var/run/docker.sock)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.DockerClientFactory(client):198 Docker host IP address is localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.DockerClientFactory(client):205 Connected to docker: \n  Server Version: 20.10.12\n  API Version: 1.41\n  Operating System: Docker Desktop\n  Total Memory: 1985 MB&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: testcontainers/ryuk:0.3.4&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container testcontainers/ryuk:0.3.4 is starting: 4ae5bfd512f21e7df22e447a2329c1d91d233c9c840a387cc0b143977b7e2212&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container testcontainers/ryuk:0.3.4 started in PT4.843866S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.u.RyukResourceReaper(init):43 Ryuk started - will monitor and terminate Testcontainers containers on JVM exit&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.DockerClientFactory(client):235 Checking the system...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.DockerClientFactory(check):256 ✔︎ Docker server version should be at least 1.6.0&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 7180a610d2d616a29219e6ec54d337ec18956e739e81b01cfaaa2ed9e228653e&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT26.679273S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-1 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-1 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.j.t.JooqLogger(info):312 \n                                      \n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@@@@@@@@@@@@@@@@  @@        @@@@@@@@@@\n@@@@@@@@@@@@@@@@@@@@        @@@@@@@@@@\n@@@@@@@@@@@@@@@@  @@  @@    @@@@@@@@@@\n@@@@@@@@@@  @@@@  @@  @@    @@@@@@@@@@\n@@@@@@@@@@        @@        @@@@@@@@@@\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@@@@@@@@@@        @@        @@@@@@@@@@\n@@@@@@@@@@    @@  @@  @@@@  @@@@@@@@@@\n@@@@@@@@@@    @@  @@  @@@@  @@@@@@@@@@\n@@@@@@@@@@        @@  @  @  @@@@@@@@@@\n@@@@@@@@@@        @@        @@@@@@@@@@\n@@@@@@@@@@@@@@@@@@@@@@@  @@@@@@@@@@@@@\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@  Thank you for using jOOQ 3.13.4\n                                      &quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@511d31a6[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-2 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-2 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 525, Xmin Raw Value: 525&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset8913102743495766944/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset8913102743495766944/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@767317755 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_fpcbuydcnc' AND plugin = 'pgoutput' AND database = 'db_fpcbuydcnc'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23907024}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset13756374217707689038/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:55651/db_fpcbuydcnc with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset13756374217707689038/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_fpcbuydcnc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_fpcbuydcnc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset13756374217707689038/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_fpcbuydcnc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 55651&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_fpcbuydcnc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_fpcbuydcnc' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_fpcbuydcnc named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_fpcbuydcnc-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CCAD0}' from transaction '525'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CCAD0}' from transaction '525'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_fpcbuydcnc'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 26 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.062'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_fpcbuydcnc'db='db_fpcbuydcnc', lsn=LSN{0/16CCAD0}, txId=525, timestamp=2023-05-20T13:44:51.374040Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CCAD0}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CCAD0}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_fpcbuydcnc named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_fpcbuydcnc-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_fpcbuydcnc named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_fpcbuydcnc-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_fpcbuydcnc\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_fpcbuydcnc\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23907024,\\\&quot;txId\\\&quot;:525,\\\&quot;ts_usec\\\&quot;:1684590291374040}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-2 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-2 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@268f0cd1[state={\&quot;[\\\&quot;db_fpcbuydcnc\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_fpcbuydcnc\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23907024,\\\&quot;txId\\\&quot;:525,\\\&quot;ts_usec\\\&quot;:1684590291374040}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-3 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-3 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 546, Xmin Raw Value: 546&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset9046372558657304054/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset9046372558657304054/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_fpcbuydcnc}]: {transaction_id=null, lsn=23907024, txId=525, ts_usec=1684590291374040}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1129898505 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_fpcbuydcnc' AND plugin = 'pgoutput' AND database = 'db_fpcbuydcnc'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23902672 Saved offset LSN : 23907024&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23910800}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset5780011331602899801/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:55651/db_fpcbuydcnc with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset5780011331602899801/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_fpcbuydcnc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_fpcbuydcnc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset5780011331602899801/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_fpcbuydcnc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 55651&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_fpcbuydcnc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_fpcbuydcnc}]: {transaction_id=null, lsn=23907024, txId=525, ts_usec=1684590291374040}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_fpcbuydcnc' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CCAD0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_fpcbuydcnc'db='db_fpcbuydcnc', lsn=LSN{0/16CCAD0}, txId=525, timestamp=2023-05-20T13:44:51.374040Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_fpcbuydcnc named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_fpcbuydcnc-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_fpcbuydcnc'db='db_fpcbuydcnc', lsn=LSN{0/16CCAD0}, txId=525, timestamp=2023-05-20T13:44:51.374040Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CCAD0}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CCAD0}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CCAD0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_fpcbuydcnc named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_fpcbuydcnc-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CCB30}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CCB30}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_fpcbuydcnc named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_fpcbuydcnc-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CCB30}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 21 records sent during previous 00:00:10.848, last recorded offset of {server=db_fpcbuydcnc} partition is {transaction_id=null, lsn_proc=23910800, messageType=INSERT, lsn_commit=23910800, lsn=23910800, txId=545, ts_usec=1684590303420536}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_fpcbuydcnc\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_fpcbuydcnc\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23910800,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23910800,\\\&quot;lsn\\\&quot;:23910800,\\\&quot;txId\\\&quot;:545,\\\&quot;ts_usec\\\&quot;:1684590303420536}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-3 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-3 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 3ea9dab01c165e98acce00208f0474e5fb1af477aadef4648a6b40330918cffe&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT32.739914S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-4 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-4 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@53c1792d[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-5 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-5 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 505, Xmin Raw Value: 505&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset6807849003893245102/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset6807849003893245102/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1311027713 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_dosmxktaqv' AND plugin = 'pgoutput' AND database = 'db_dosmxktaqv'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset5134555836395899576/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:55775/db_dosmxktaqv with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset5134555836395899576/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset5134555836395899576/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 55775&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_dosmxktaqv' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dosmxktaqv named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dosmxktaqv-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_dosmxktaqv'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.018'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_dosmxktaqv'db='db_dosmxktaqv', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:46:05.342463Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dosmxktaqv named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dosmxktaqv-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dosmxktaqv named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dosmxktaqv-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_dosmxktaqv\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_dosmxktaqv\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590365342463}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-5 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-5 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type LEGACY.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(generateGlobalState):84 Legacy state converted to global state.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_random_models_random, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@717646f1[state={\&quot;[\\\&quot;db_dosmxktaqv\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_dosmxktaqv\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590365342463}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-6 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-6 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema_random\&quot;, table \&quot;models_random\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_random_pkey, Column: id_random, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 526, Xmin Raw Value: 526&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.a.i.s.r.DbSourceDiscoverUtil(logSourceSchemaChange):82 Source schema changed for table models_schema_random.models_random! Potential mismatches: [id_random, make_id_random]. Actual schema: {\&quot;type\&quot;:\&quot;object\&quot;,\&quot;properties\&quot;:{\&quot;model_random\&quot;:{\&quot;type\&quot;:\&quot;string\&quot;},\&quot;id_random\&quot;:{\&quot;type\&quot;:\&quot;number\&quot;,\&quot;airbyte_type\&quot;:\&quot;integer\&quot;},\&quot;make_id_random\&quot;:{\&quot;type\&quot;:\&quot;number\&quot;,\&quot;airbyte_type\&quot;:\&quot;integer\&quot;}}}. Catalog schema: {\&quot;type\&quot;:\&quot;object\&quot;,\&quot;properties\&quot;:{\&quot;model_random\&quot;:{\&quot;type\&quot;:\&quot;string\&quot;},\&quot;id_random\&quot;:{\&quot;type\&quot;:\&quot;number\&quot;},\&quot;make_id_random\&quot;:{\&quot;type\&quot;:\&quot;number\&quot;}}}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset3383506785705169182/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset3383506785705169182/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_dosmxktaqv}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684590365342463}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@955901595 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_dosmxktaqv' AND plugin = 'pgoutput' AND database = 'db_dosmxktaqv'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23902672 Saved offset LSN : 23903320&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23907120}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getSnapshotIterators):62 Running snapshot for 1 new tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-dummy-state-offset13819604412599526874/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:55775/db_dosmxktaqv with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-dummy-state-offset13819604412599526874/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-dummy-state-offset13819604412599526874/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema_random.models_random\\E\\.(\\Qmodel_random\\E|\\Qid_random\\E|\\Qmake_id_random\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 55775&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema_random.models_random\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial_only&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_dosmxktaqv' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=null, catalogXmin=null]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dosmxktaqv named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dosmxktaqv-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialOnlySnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(setSnapshotTransactionIsolationLevel):235 Setting isolation level&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(setSnapshotTransactionIsolationLevel):237 Opening transaction with statement SET TRANSACTION ISOLATION LEVEL SERIALIZABLE, READ ONLY, DEFERRABLE;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CCB30}' from transaction '526'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CCB30}' from transaction '526'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema_random' of catalog 'db_dosmxktaqv'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema_random.models_random' using select statement: 'SELECT \&quot;id_random\&quot;, \&quot;make_id_random\&quot;, \&quot;model_random\&quot; FROM \&quot;models_schema_random\&quot;.\&quot;models_random\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema_random.models_random' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema_random.models_random' (1 of 1 tables); total duration '00:00:00.013'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_dosmxktaqv'db='db_dosmxktaqv', lsn=LSN{0/16CCB30}, txId=526, timestamp=2023-05-20T13:46:17.057482Z, snapshot=FALSE, schema=models_schema_random, table=models_random], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema_random.models_random' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):115 Streaming is not enabled in correct configuration&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveStateAfterCompletionOfSnapshotOfNewStreams):60 Snapshot of new tables is complete, saving state&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset2894336727408797707/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:55775/db_dosmxktaqv with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset2894336727408797707/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset2894336727408797707/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E),\\Qmodels_schema_random.models_random\\E\\.(\\Qmodel_random\\E|\\Qid_random\\E|\\Qmake_id_random\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 55775&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E,\\Qmodels_schema_random.models_random\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_dosmxktaqv}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684590365342463}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_dosmxktaqv' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_dosmxktaqv'db='db_dosmxktaqv', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:46:05.342463Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dosmxktaqv named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dosmxktaqv-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_dosmxktaqv'db='db_dosmxktaqv', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:46:05.342463Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema_random.models_random' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dosmxktaqv named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dosmxktaqv-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema_random.models_random' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CBC80}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CBC80}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dosmxktaqv named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dosmxktaqv-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CBC80}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 21 records sent during previous 00:00:10.714, last recorded offset of {server=db_dosmxktaqv} partition is {transaction_id=null, lsn_proc=23907120, messageType=INSERT, lsn_commit=23907120, lsn=23907120, txId=525, ts_usec=1684590376496431}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_dosmxktaqv\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_dosmxktaqv\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23907120,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23907120,\\\&quot;lsn\\\&quot;:23907120,\\\&quot;txId\\\&quot;:525,\\\&quot;ts_usec\\\&quot;:1684590376496431}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-6 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-6 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type LEGACY.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(generateGlobalState):84 Legacy state converted to global state.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@177c2091[state={\&quot;[\\\&quot;db_dosmxktaqv\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_dosmxktaqv\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23907120,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23907120,\\\&quot;lsn\\\&quot;:23907120,\\\&quot;txId\\\&quot;:525,\\\&quot;ts_usec\\\&quot;:1684590376496431}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-7 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-7 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema_random\&quot;, table \&quot;models_random\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_random_pkey, Column: id_random, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 567, Xmin Raw Value: 567&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.a.i.s.r.DbSourceDiscoverUtil(logSourceSchemaChange):82 Source schema changed for table models_schema_random.models_random! Potential mismatches: [id_random, make_id_random]. Actual schema: {\&quot;type\&quot;:\&quot;object\&quot;,\&quot;properties\&quot;:{\&quot;model_random\&quot;:{\&quot;type\&quot;:\&quot;string\&quot;},\&quot;id_random\&quot;:{\&quot;type\&quot;:\&quot;number\&quot;,\&quot;airbyte_type\&quot;:\&quot;integer\&quot;},\&quot;make_id_random\&quot;:{\&quot;type\&quot;:\&quot;number\&quot;,\&quot;airbyte_type\&quot;:\&quot;integer\&quot;}}}. Catalog schema: {\&quot;type\&quot;:\&quot;object\&quot;,\&quot;properties\&quot;:{\&quot;model_random\&quot;:{\&quot;type\&quot;:\&quot;string\&quot;},\&quot;id_random\&quot;:{\&quot;type\&quot;:\&quot;number\&quot;},\&quot;make_id_random\&quot;:{\&quot;type\&quot;:\&quot;number\&quot;}}}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset10086517235222511510/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset10086517235222511510/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_dosmxktaqv}]: {transaction_id=null, lsn_proc=23907120, messageType=INSERT, lsn_commit=23907120, lsn=23907120, txId=525, ts_usec=1684590376496431}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1630145865 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_dosmxktaqv' AND plugin = 'pgoutput' AND database = 'db_dosmxktaqv'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23903320 Saved offset LSN : 23907120&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23914816}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset18211205304326490710/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:55775/db_dosmxktaqv with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset18211205304326490710/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset18211205304326490710/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E),\\Qmodels_schema_random.models_random\\E\\.(\\Qmodel_random\\E|\\Qid_random\\E|\\Qmake_id_random\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 55775&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_dosmxktaqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E,\\Qmodels_schema_random.models_random\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_dosmxktaqv}]: {transaction_id=null, lsn_proc=23907120, messageType=INSERT, lsn_commit=23907120, lsn=23907120, txId=525, ts_usec=1684590376496431}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_dosmxktaqv' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CCB30}, catalogXmin=524]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_dosmxktaqv'db='db_dosmxktaqv', lsn=LSN{0/16CCB30}, txId=525, messageType=INSERT, lastCommitLsn=LSN{0/16CCB30}, timestamp=2023-05-20T13:46:16.496431Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=LSN{0/16CCB30}, lastCommitLsn=LSN{0/16CCB30}, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dosmxktaqv named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dosmxktaqv-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_dosmxktaqv'db='db_dosmxktaqv', lsn=LSN{0/16CCB30}, txId=525, messageType=INSERT, lastCommitLsn=LSN{0/16CCB30}, timestamp=2023-05-20T13:46:16.496431Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=LSN{0/16CCB30}, lastCommitLsn=LSN{0/16CCB30}, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema_random.models_random' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CCB30}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'LSN{0/16CCB30}' and last change LSN 'LSN{0/16CCB30}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CCB30}, catalogXmin=524]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dosmxktaqv named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dosmxktaqv-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema_random.models_random' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CCB90}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):108 Received COMMIT LSN 'LSN{0/16CCC48}' larger than than last stored commit LSN 'LSN{0/16CCB30}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):120 Will restart from LSN 'LSN{0/16CCB90}' that is start of the first unprocessed transaction&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CCB90}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dosmxktaqv named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dosmxktaqv-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CCB90}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 41 records sent during previous 00:00:10.262, last recorded offset of {server=db_dosmxktaqv} partition is {transaction_id=null, lsn_proc=23914816, messageType=INSERT, lsn_commit=23914816, lsn=23914816, txId=566, ts_usec=1684590413989246}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_dosmxktaqv\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_dosmxktaqv\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23914816,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23914816,\\\&quot;lsn\\\&quot;:23914816,\\\&quot;txId\\\&quot;:566,\\\&quot;ts_usec\\\&quot;:1684590413989246}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-7 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-7 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: ca3e17793d181f4c53c9df276461a29f4506e0cf17812e065539745b016a1adf&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT6.8748S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-8 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-8 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@5246532[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-9 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-9 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 505, Xmin Raw Value: 505&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset12662918516644239054/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset12662918516644239054/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@40047131 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_goyflnakqr' AND plugin = 'pgoutput' AND database = 'db_goyflnakqr'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset3882529325203813785/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:55952/db_goyflnakqr with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset3882529325203813785/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_goyflnakqr&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_goyflnakqr&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset3882529325203813785/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_goyflnakqr&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 55952&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_goyflnakqr&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_goyflnakqr' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_goyflnakqr named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_goyflnakqr-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_goyflnakqr'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.011'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_goyflnakqr'db='db_goyflnakqr', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:47:25.677573Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_goyflnakqr named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_goyflnakqr-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_goyflnakqr named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_goyflnakqr-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_goyflnakqr\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_goyflnakqr\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590445677573}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-9 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-9 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@496d7bd9[state={\&quot;[\\\&quot;db_goyflnakqr\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_goyflnakqr\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590445677573}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-10 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-10 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 506, Xmin Raw Value: 506&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset5889909025960079736/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset5889909025960079736/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_goyflnakqr}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684590445677573}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@445181082 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_goyflnakqr' AND plugin = 'pgoutput' AND database = 'db_goyflnakqr'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23902672 Saved offset LSN : 23903320&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903360}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset14843974780844317183/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:55952/db_goyflnakqr with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset14843974780844317183/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_goyflnakqr&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_goyflnakqr&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset14843974780844317183/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_goyflnakqr&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 55952&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_goyflnakqr&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_goyflnakqr}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684590445677573}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_goyflnakqr' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_goyflnakqr'db='db_goyflnakqr', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:47:25.677573Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_goyflnakqr named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_goyflnakqr-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_goyflnakqr'db='db_goyflnakqr', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:47:25.677573Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_goyflnakqr named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_goyflnakqr-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 No records were returned by Debezium in the timeout seconds 30, closing the engine and iterator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_goyflnakqr named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_goyflnakqr-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(computeNext):107 no record found. polling again.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_goyflnakqr\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_goyflnakqr\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590445677573}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-10 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-10 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: f5c6537248429836d0223765b159feec7b6776cdc4bb4857249f964a9f883249&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT5.571302S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-11 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-11 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-12 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-12 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(lambda$getCheckOperations$1):138 Attempting to get metadata from the database to see if we can connect.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1259816781 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_wubiomrztc' AND plugin = 'pgoutput' AND database = 'db_wubiomrztc'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getCheckOperations$6):328 Attempting to find the publication using the query: HikariProxyPreparedStatement@1889137816 wrapping SELECT * FROM pg_publication WHERE pubname = 'publication'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-12 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-12 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 22a948dfbf44fc76657aa2919c09c1174148470a4b8417519020711baa494d33&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT6.193238S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-13 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-13 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models_2, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@25cc6b0[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-14 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-14 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema.models_2, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models_2\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_2_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 512, Xmin Raw Value: 512&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset1539261705899524558/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset1539261705899524558/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@936120380 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_dtzldmyvqv' AND plugin = 'pgoutput' AND database = 'db_dtzldmyvqv'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23919344}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset5099729614159245571/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(queryTableFullRefresh):112 Queueing query for table: models_2&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:55981/db_dtzldmyvqv with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset5099729614159245571/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_dtzldmyvqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_dtzldmyvqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset5099729614159245571/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_dtzldmyvqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 55981&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_dtzldmyvqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_dtzldmyvqv' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dtzldmyvqv named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dtzldmyvqv-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models_2 to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CFAF0}' from transaction '512'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CFAF0}' from transaction '512'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_dtzldmyvqv'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.012'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_dtzldmyvqv'db='db_dtzldmyvqv', lsn=LSN{0/16CFAF0}, txId=512, timestamp=2023-05-20T13:48:36.361755Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CFAF0}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CFAF0}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dtzldmyvqv named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dtzldmyvqv-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dtzldmyvqv named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dtzldmyvqv-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_dtzldmyvqv\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_dtzldmyvqv\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23919344,\\\&quot;txId\\\&quot;:512,\\\&quot;ts_usec\\\&quot;:1684590516361755}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.c.u.CompositeIterator(lambda$emitStartStreamStatus$1):155 STARTING -&gt; models_schema_models_2&quot;}}
{&quot;type&quot;:&quot;TRACE&quot;,&quot;trace&quot;:{&quot;type&quot;:&quot;STREAM_STATUS&quot;,&quot;emitted_at&quot;:1.684590526877E12,&quot;stream_status&quot;:{&quot;stream_descriptor&quot;:{&quot;name&quot;:&quot;models_2&quot;,&quot;namespace&quot;:&quot;models_schema&quot;},&quot;status&quot;:&quot;STARTED&quot;}}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.RelationalDbQueryUtils(lambda$queryTable$0):73 Queueing query: SELECT \&quot;id\&quot;,\&quot;make_id\&quot;,\&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models_2\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.c.u.CompositeIterator(lambda$emitRunningStreamStatus$0):148 RUNNING -&gt; models_schema_models_2&quot;}}
{&quot;type&quot;:&quot;TRACE&quot;,&quot;trace&quot;:{&quot;type&quot;:&quot;STREAM_STATUS&quot;,&quot;emitted_at&quot;:1.684590526919E12,&quot;stream_status&quot;:{&quot;stream_descriptor&quot;:{&quot;name&quot;:&quot;models_2&quot;,&quot;namespace&quot;:&quot;models_schema&quot;},&quot;status&quot;:&quot;RUNNING&quot;}}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.c.u.CompositeIterator(lambda$emitCompleteStreamStatus$2):162 COMPLETE -&gt; models_schema_models_2&quot;}}
{&quot;type&quot;:&quot;TRACE&quot;,&quot;trace&quot;:{&quot;type&quot;:&quot;STREAM_STATUS&quot;,&quot;emitted_at&quot;:1.684590526924E12,&quot;stream_status&quot;:{&quot;stream_descriptor&quot;:{&quot;name&quot;:&quot;models_2&quot;,&quot;namespace&quot;:&quot;models_schema&quot;},&quot;status&quot;:&quot;COMPLETE&quot;}}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-14 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-14 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@62b0059[state={\&quot;[\\\&quot;db_dtzldmyvqv\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_dtzldmyvqv\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23919344,\\\&quot;txId\\\&quot;:512,\\\&quot;ts_usec\\\&quot;:1684590516361755}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-15 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-15 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema.models_2, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models_2\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_2_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 514, Xmin Raw Value: 514&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset18064088365320764263/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset18064088365320764263/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_dtzldmyvqv}]: {transaction_id=null, lsn=23919344, txId=512, ts_usec=1684590516361755}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@616186848 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_dtzldmyvqv' AND plugin = 'pgoutput' AND database = 'db_dtzldmyvqv'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23902672 Saved offset LSN : 23919344&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23919568}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset1161018683041412594/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(queryTableFullRefresh):112 Queueing query for table: models_2&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:55981/db_dtzldmyvqv with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset1161018683041412594/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_dtzldmyvqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_dtzldmyvqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset1161018683041412594/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_dtzldmyvqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 55981&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_dtzldmyvqv&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_dtzldmyvqv}]: {transaction_id=null, lsn=23919344, txId=512, ts_usec=1684590516361755}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_dtzldmyvqv' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CFAF0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_dtzldmyvqv'db='db_dtzldmyvqv', lsn=LSN{0/16CFAF0}, txId=512, timestamp=2023-05-20T13:48:36.361755Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dtzldmyvqv named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dtzldmyvqv-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_dtzldmyvqv'db='db_dtzldmyvqv', lsn=LSN{0/16CFAF0}, txId=512, timestamp=2023-05-20T13:48:36.361755Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CFAF0}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CFAF0}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CFAF0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dtzldmyvqv named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dtzldmyvqv-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CFB18}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CFB18}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_dtzldmyvqv named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_dtzldmyvqv-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CFB18}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 2 records sent during previous 00:00:10.699, last recorded offset of {server=db_dtzldmyvqv} partition is {transaction_id=null, lsn_proc=23919568, messageType=INSERT, lsn_commit=23919568, lsn=23919568, txId=513, ts_usec=1684590526946235}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_dtzldmyvqv\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_dtzldmyvqv\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23919568,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23919568,\\\&quot;lsn\\\&quot;:23919568,\\\&quot;txId\\\&quot;:513,\\\&quot;ts_usec\\\&quot;:1684590526946235}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.c.u.CompositeIterator(lambda$emitStartStreamStatus$1):155 STARTING -&gt; models_schema_models_2&quot;}}
{&quot;type&quot;:&quot;TRACE&quot;,&quot;trace&quot;:{&quot;type&quot;:&quot;STREAM_STATUS&quot;,&quot;emitted_at&quot;:1.684590547908E12,&quot;stream_status&quot;:{&quot;stream_descriptor&quot;:{&quot;name&quot;:&quot;models_2&quot;,&quot;namespace&quot;:&quot;models_schema&quot;},&quot;status&quot;:&quot;STARTED&quot;}}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.RelationalDbQueryUtils(lambda$queryTable$0):73 Queueing query: SELECT \&quot;id\&quot;,\&quot;make_id\&quot;,\&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models_2\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.c.u.CompositeIterator(lambda$emitRunningStreamStatus$0):148 RUNNING -&gt; models_schema_models_2&quot;}}
{&quot;type&quot;:&quot;TRACE&quot;,&quot;trace&quot;:{&quot;type&quot;:&quot;STREAM_STATUS&quot;,&quot;emitted_at&quot;:1.684590547925E12,&quot;stream_status&quot;:{&quot;stream_descriptor&quot;:{&quot;name&quot;:&quot;models_2&quot;,&quot;namespace&quot;:&quot;models_schema&quot;},&quot;status&quot;:&quot;RUNNING&quot;}}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.c.u.CompositeIterator(lambda$emitCompleteStreamStatus$2):162 COMPLETE -&gt; models_schema_models_2&quot;}}
{&quot;type&quot;:&quot;TRACE&quot;,&quot;trace&quot;:{&quot;type&quot;:&quot;STREAM_STATUS&quot;,&quot;emitted_at&quot;:1.684590547929E12,&quot;stream_status&quot;:{&quot;stream_descriptor&quot;:{&quot;name&quot;:&quot;models_2&quot;,&quot;namespace&quot;:&quot;models_schema&quot;},&quot;status&quot;:&quot;COMPLETE&quot;}}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-15 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-15 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: a5540d83ffbfd12e669f6ddbe1d4ec09ccb62ab4f65916a9d0d059b9033f73a3&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT5.797439S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-16 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-16 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-17 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-17 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema.models_2, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverPrimaryKeys):266 Discover primary keys for tables: [models_random, models, models_2]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-17 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-17 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: c2198e61f0e66ecb30688b9a19db472241d991724b849e40f1f6c7479c2e409f&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT6.226707S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-18 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-18 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@5e409078[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-19 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-19 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 505, Xmin Raw Value: 505&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset14802370360006719558/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset14802370360006719558/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1590343237 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_ghwjcrmqxo' AND plugin = 'pgoutput' AND database = 'db_ghwjcrmqxo'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset9420835723244568083/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56006/db_ghwjcrmqxo with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset9420835723244568083/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_ghwjcrmqxo&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_ghwjcrmqxo&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset9420835723244568083/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_ghwjcrmqxo&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56006&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_ghwjcrmqxo&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_ghwjcrmqxo' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_ghwjcrmqxo named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_ghwjcrmqxo-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_ghwjcrmqxo'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.011'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_ghwjcrmqxo'db='db_ghwjcrmqxo', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:49:28.074807Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_ghwjcrmqxo named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_ghwjcrmqxo-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_ghwjcrmqxo named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_ghwjcrmqxo-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_ghwjcrmqxo\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_ghwjcrmqxo\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590568074807}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-19 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-19 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@1e1f9de4[state={\&quot;[\\\&quot;db_ghwjcrmqxo\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_ghwjcrmqxo\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590568074807}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-20 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-20 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 507, Xmin Raw Value: 507&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset7613660921677910411/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset7613660921677910411/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_ghwjcrmqxo}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684590568074807}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@587820621 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_ghwjcrmqxo' AND plugin = 'pgoutput' AND database = 'db_ghwjcrmqxo'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23902672 Saved offset LSN : 23903320&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903472}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset8413556794627484640/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56006/db_ghwjcrmqxo with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset8413556794627484640/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_ghwjcrmqxo&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_ghwjcrmqxo&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset8413556794627484640/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_ghwjcrmqxo&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56006&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_ghwjcrmqxo&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_ghwjcrmqxo}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684590568074807}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_ghwjcrmqxo' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_ghwjcrmqxo'db='db_ghwjcrmqxo', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:49:28.074807Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_ghwjcrmqxo named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_ghwjcrmqxo-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_ghwjcrmqxo'db='db_ghwjcrmqxo', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:49:28.074807Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_ghwjcrmqxo named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_ghwjcrmqxo-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CBC80}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CBC80}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_ghwjcrmqxo named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_ghwjcrmqxo-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CBC80}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 3 records sent during previous 00:00:10.712, last recorded offset of {server=db_ghwjcrmqxo} partition is {transaction_id=null, lsn_proc=23903472, messageType=DELETE, lsn_commit=23903472, lsn=23903472, txId=506, ts_usec=1684590578606648}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_ghwjcrmqxo\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_ghwjcrmqxo\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23903472,\\\&quot;messageType\\\&quot;:\\\&quot;DELETE\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23903472,\\\&quot;lsn\\\&quot;:23903472,\\\&quot;txId\\\&quot;:506,\\\&quot;ts_usec\\\&quot;:1684590578606648}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-20 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-20 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: c27a882f681e83f49232a602ec46237ec958aca3972cf763a33a01047306c9aa&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT5.818347S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-21 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-21 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@ff8df3[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-22 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-22 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 506, Xmin Raw Value: 506&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset8669990751656956333/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset8669990751656956333/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1365429449 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_fjwjkghjos' AND plugin = 'pgoutput' AND database = 'db_fjwjkghjos'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903752}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset6686247092977109224/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56054/db_fjwjkghjos with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset6686247092977109224/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_fjwjkghjos&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_fjwjkghjos&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset6686247092977109224/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_fjwjkghjos&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56054&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_fjwjkghjos&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_fjwjkghjos' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_fjwjkghjos named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_fjwjkghjos-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CBE08}' from transaction '506'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CBE08}' from transaction '506'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_fjwjkghjos'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 0 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.006'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_fjwjkghjos'db='db_fjwjkghjos', lsn=LSN{0/16CBE08}, txId=506, timestamp=2023-05-20T13:50:09.094Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBE08}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBE08}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_fjwjkghjos named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_fjwjkghjos-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_fjwjkghjos named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_fjwjkghjos-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_fjwjkghjos\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_fjwjkghjos\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903752,\\\&quot;txId\\\&quot;:506,\\\&quot;ts_usec\\\&quot;:1684590609094000}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-22 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-22 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 61acdaca2958e8a44f6291291173e020bea9abb9f3103c22a32b1447f415aa58&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT6.140994S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-23 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-23 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-24 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-24 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@2e178fb6[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-25 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-25 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 505, Xmin Raw Value: 505&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset1344671270572505615/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset1344671270572505615/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@2104081166 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_ztxlsunziq' AND plugin = 'pgoutput' AND database = 'db_ztxlsunziq'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset16148061711284831409/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56066/db_ztxlsunziq with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset16148061711284831409/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_ztxlsunziq&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_ztxlsunziq&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset16148061711284831409/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_ztxlsunziq&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56066&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_ztxlsunziq&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_ztxlsunziq' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_ztxlsunziq named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_ztxlsunziq-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_ztxlsunziq'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.011'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_ztxlsunziq'db='db_ztxlsunziq', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:50:29.832069Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_ztxlsunziq named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_ztxlsunziq-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_ztxlsunziq named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_ztxlsunziq-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_ztxlsunziq\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_ztxlsunziq\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590629832069}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-25 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-25 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 498f8d693ac4df949ee77411da5b2eb29adc6f2d0a2c34d620a853bffe09e68a&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT5.839905S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-26 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-26 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@4da093f5[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-27 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-27 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 505, Xmin Raw Value: 505&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset18123979193654590051/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset18123979193654590051/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@925141804 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_eindrcbptk' AND plugin = 'pgoutput' AND database = 'db_eindrcbptk'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset15645772248247069278/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56082/db_eindrcbptk with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset15645772248247069278/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_eindrcbptk&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_eindrcbptk&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset15645772248247069278/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_eindrcbptk&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56082&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_eindrcbptk&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_eindrcbptk' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_eindrcbptk named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_eindrcbptk-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_eindrcbptk'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.011'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_eindrcbptk'db='db_eindrcbptk', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:50:50.453407Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_eindrcbptk named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_eindrcbptk-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_eindrcbptk named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_eindrcbptk-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_eindrcbptk\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_eindrcbptk\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590650453407}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-27 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-27 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@1a7ba443[state={\&quot;[\\\&quot;db_eindrcbptk\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_eindrcbptk\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590650453407}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-28 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-28 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 507, Xmin Raw Value: 507&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset8586595969162887561/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset8586595969162887561/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_eindrcbptk}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684590650453407}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1027761720 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_eindrcbptk' AND plugin = 'pgoutput' AND database = 'db_eindrcbptk'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23902672 Saved offset LSN : 23903320&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903496}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset10351039057402502176/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56082/db_eindrcbptk with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset10351039057402502176/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_eindrcbptk&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_eindrcbptk&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset10351039057402502176/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_eindrcbptk&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56082&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_eindrcbptk&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_eindrcbptk}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684590650453407}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_eindrcbptk' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_eindrcbptk'db='db_eindrcbptk', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:50:50.453407Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_eindrcbptk named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_eindrcbptk-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_eindrcbptk'db='db_eindrcbptk', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:50:50.453407Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_eindrcbptk named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_eindrcbptk-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CBC80}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CBC80}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_eindrcbptk named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_eindrcbptk-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CBC80}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 2 records sent during previous 00:00:10.677, last recorded offset of {server=db_eindrcbptk} partition is {transaction_id=null, lsn_proc=23903496, messageType=UPDATE, lsn_commit=23903496, lsn=23903496, txId=506, ts_usec=1684590660977140}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_eindrcbptk\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_eindrcbptk\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23903496,\\\&quot;messageType\\\&quot;:\\\&quot;UPDATE\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23903496,\\\&quot;lsn\\\&quot;:23903496,\\\&quot;txId\\\&quot;:506,\\\&quot;ts_usec\\\&quot;:1684590660977140}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-28 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-28 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 9b5882ef11f03f11e231b889ea14afa9ad01a29c886cb583da12d15b44d7d7cc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT5.559389S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-29 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-29 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_time_stamp_table, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@5fa7cb3[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-30 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-30 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema.time_stamp_table, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;time_stamp_table\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: time_stamp_table_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 512, Xmin Raw Value: 512&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.a.i.s.r.DbSourceDiscoverUtil(logSourceSchemaChange):82 Source schema changed for table models_schema.time_stamp_table! Potential mismatches: [id]. Actual schema: {\&quot;type\&quot;:\&quot;object\&quot;,\&quot;properties\&quot;:{\&quot;name\&quot;:{\&quot;type\&quot;:\&quot;string\&quot;},\&quot;created_at\&quot;:{\&quot;type\&quot;:\&quot;string\&quot;,\&quot;format\&quot;:\&quot;date-time\&quot;,\&quot;airbyte_type\&quot;:\&quot;timestamp_with_timezone\&quot;},\&quot;id\&quot;:{\&quot;type\&quot;:\&quot;number\&quot;,\&quot;airbyte_type\&quot;:\&quot;integer\&quot;}}}. Catalog schema: {\&quot;type\&quot;:\&quot;object\&quot;,\&quot;properties\&quot;:{\&quot;name\&quot;:{\&quot;type\&quot;:\&quot;string\&quot;},\&quot;created_at\&quot;:{\&quot;type\&quot;:\&quot;string\&quot;,\&quot;format\&quot;:\&quot;date-time\&quot;,\&quot;airbyte_type\&quot;:\&quot;timestamp_with_timezone\&quot;},\&quot;id\&quot;:{\&quot;type\&quot;:\&quot;number\&quot;}}}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset1257689215965767343/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset1257689215965767343/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@867222659 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_knsposmjcz' AND plugin = 'pgoutput' AND database = 'db_knsposmjcz'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23926392}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset7538268703315391566/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56101/db_knsposmjcz with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset7538268703315391566/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_knsposmjcz&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_knsposmjcz&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset7538268703315391566/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_knsposmjcz&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.time_stamp_table\\E\\.(\\Qname\\E|\\Qcreated_at\\E|\\Qid\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56101&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_knsposmjcz&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.time_stamp_table\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_knsposmjcz' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_knsposmjcz named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_knsposmjcz-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.DateTimeConverter(convertToTimestampWithTimezone):81 Unknown class for Timestamp with time zone data typeclass java.lang.String&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.time_stamp_table to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.time_stamp_table]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16D1678}' from transaction '512'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16D1678}' from transaction '512'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_knsposmjcz'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.time_stamp_table' using select statement: 'SELECT \&quot;id\&quot;, \&quot;name\&quot;, \&quot;created_at\&quot; FROM \&quot;models_schema\&quot;.\&quot;time_stamp_table\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.time_stamp_table' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.time_stamp_table' (1 of 1 tables); total duration '00:00:00.013'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_knsposmjcz'db='db_knsposmjcz', lsn=LSN{0/16D1678}, txId=512, timestamp=2023-05-20T13:51:31.606313Z, snapshot=FALSE, schema=models_schema, table=time_stamp_table], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.time_stamp_table' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16D1678}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16D1678}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_knsposmjcz named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_knsposmjcz-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.time_stamp_table' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_knsposmjcz named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_knsposmjcz-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_knsposmjcz\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_knsposmjcz\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23926392,\\\&quot;txId\\\&quot;:512,\\\&quot;ts_usec\\\&quot;:1684590691606313}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-30 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-30 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 7d402b14253576a52d7eae6f0b4ae054df3c7c216f1b15f416f7101c938ee64a&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT6.390584S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-31 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-31 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-32 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-32 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(lambda$getCheckOperations$1):138 Attempting to get metadata from the database to see if we can connect.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@2067495195 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_czjszndfdy' AND plugin = 'pgoutput' AND database = 'db_czjszndfdy'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getCheckOperations$6):328 Attempting to find the publication using the query: HikariProxyPreparedStatement@1359881741 wrapping SELECT * FROM pg_publication WHERE pubname = 'publication'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-32 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-32 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 125010b8c6bc3b99d322764801bef76c4f79ddcd774ed56e6f5e8b57f49b6e08&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT6.390821S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-33 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-33 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-34 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-34 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverPrimaryKeys):266 Discover primary keys for tables: [models_random, models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-34 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-34 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 5968e1f28ac64020e7cb4db07f5ca1fb387bc56b32ecceef86f793687283d0fd&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT6.054153S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-35 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-35 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-36 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-36 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: []&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(lambda$getCheckOperations$1):138 Attempting to get metadata from the database to see if we can connect.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@568692378 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_mgemsfgqbu' AND plugin = 'pgoutput' AND database = 'db_mgemsfgqbu'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getCheckOperations$6):328 Attempting to find the publication using the query: HikariProxyPreparedStatement@1930136826 wrapping SELECT * FROM pg_publication WHERE pubname = 'publication'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(check):101 Exception while checking connection: io.airbyte.commons.exceptions.ConfigErrorException: Expected exactly one publication but found 0. Please read the docs and add a publication to your database.\n\tat io.airbyte.integrations.source.postgres.PostgresSource.lambda$getCheckOperations$7(PostgresSource.java:334) ~[main/:?]\n\tat io.airbyte.integrations.source.relationaldb.AbstractDbSource.check(AbstractDbSource.java:87) ~[io.airbyte.airbyte-integrations.connectors-source-relational-db-0.44.4.jar:?]\n\tat io.airbyte.integrations.source.postgres.PostgresSource.check(PostgresSource.java:527) ~[main/:?]\n\tat io.airbyte.integrations.source.postgres.CdcPostgresSourceTest.testCheckWithoutPublication(CdcPostgresSourceTest.java:218) ~[test/:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]\n\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]\n\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727) ~[junit-platform-commons-1.9.1.jar:1.9.1]\n\tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:86) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat java.util.ArrayList.forEach(ArrayList.java:1511) ~[?:?]\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat java.util.ArrayList.forEach(ArrayList.java:1511) ~[?:?]\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:62) ~[?:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]\n\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36) ~[?:?]\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24) ~[?:?]\n\tat org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33) ~[?:?]\n\tat org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94) ~[?:?]\n\tat jdk.proxy2.$Proxy5.stop(Unknown Source) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60) ~[?:?]\n\tat org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56) ~[?:?]\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:113) ~[?:?]\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:65) ~[?:?]\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69) ~[gradle-worker.jar:?]\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74) ~[gradle-worker.jar:?]\n&quot;,&quot;stack_trace&quot;:&quot;io.airbyte.commons.exceptions.ConfigErrorException: Expected exactly one publication but found 0. Please read the docs and add a publication to your database.\n\tat io.airbyte.integrations.source.postgres.PostgresSource.lambda$getCheckOperations$7(PostgresSource.java:334)\n\tat io.airbyte.integrations.source.relationaldb.AbstractDbSource.check(AbstractDbSource.java:87)\n\tat io.airbyte.integrations.source.postgres.PostgresSource.check(PostgresSource.java:527)\n\tat io.airbyte.integrations.source.postgres.CdcPostgresSourceTest.testCheckWithoutPublication(CdcPostgresSourceTest.java:218)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727)\n\tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:86)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)\n\tat org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)\n\tat org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75)\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:62)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)\n\tat org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)\n\tat jdk.proxy2/jdk.proxy2.$Proxy5.stop(Unknown Source)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60)\n\tat org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56)\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:113)\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:65)\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69)\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74)\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-36 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-36 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: ca3577b095afb1015c46473b18defe0a07871f0ab14db9371c40f4f8bca22225&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT6.246951S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-37 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-37 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@3f851ccf[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-38 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-38 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 505, Xmin Raw Value: 505&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset3316230643035674041/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset3316230643035674041/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@2114641717 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_qaookfpaht' AND plugin = 'pgoutput' AND database = 'db_qaookfpaht'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset9228302158914860867/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56124/db_qaookfpaht with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset9228302158914860867/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_qaookfpaht&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_qaookfpaht&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset9228302158914860867/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_qaookfpaht&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56124&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_qaookfpaht&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_qaookfpaht' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_qaookfpaht named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_qaookfpaht-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_qaookfpaht'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.011'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_qaookfpaht'db='db_qaookfpaht', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:52:23.008566Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_qaookfpaht named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_qaookfpaht-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_qaookfpaht named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_qaookfpaht-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590743008566}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-38 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-38 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@51baea92[state={\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684590743008566}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-39 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-39 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 20515, Xmin Raw Value: 20515&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset7204248830657590290/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset7204248830657590290/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_qaookfpaht}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684590743008566}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@818325520 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_qaookfpaht' AND plugin = 'pgoutput' AND database = 'db_qaookfpaht'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23902672 Saved offset LSN : 23903320&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=27750072}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset3485066369482048015/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56124/db_qaookfpaht with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset3485066369482048015/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_qaookfpaht&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_qaookfpaht&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset3485066369482048015/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_qaookfpaht&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56124&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_qaookfpaht&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_qaookfpaht}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684590743008566}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_qaookfpaht' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_qaookfpaht'db='db_qaookfpaht', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:52:23.008566Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_qaookfpaht named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_qaookfpaht-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_qaookfpaht'db='db_qaookfpaht', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T13:52:23.008566Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_qaookfpaht named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_qaookfpaht-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CBC80}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CBC80}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.c.PostgresReplicationConnection(startStreaming):346 Failed to start replication stream at LSN{0/16CBC58}, waiting for PT10S ms and retrying, attempt number 1 over 6&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_qaookfpaht named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_qaookfpaht-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CBC80}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 96 records sent during previous 00:00:10.686, last recorded offset of {server=db_qaookfpaht} partition is {transaction_id=null, lsn_proc=23920784, messageType=INSERT, lsn_commit=23920784, lsn=23920784, txId=600, ts_usec=1684590756794090}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23920784,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23920784,\\\&quot;lsn\\\&quot;:23920784,\\\&quot;txId\\\&quot;:600,\\\&quot;ts_usec\\\&quot;:1684590756794090}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24164240,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24164240,\\\&quot;lsn\\\&quot;:24164240,\\\&quot;txId\\\&quot;:1906,\\\&quot;ts_usec\\\&quot;:1684590800053759}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24316048,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24316048,\\\&quot;lsn\\\&quot;:24316048,\\\&quot;txId\\\&quot;:2720,\\\&quot;ts_usec\\\&quot;:1684590828477975}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24473640,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24473640,\\\&quot;lsn\\\&quot;:24473640,\\\&quot;txId\\\&quot;:3561,\\\&quot;ts_usec\\\&quot;:1684590859018881}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24484152,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24484152,\\\&quot;lsn\\\&quot;:24484152,\\\&quot;txId\\\&quot;:3618,\\\&quot;ts_usec\\\&quot;:1684590861308473}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24730720,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24730720,\\\&quot;lsn\\\&quot;:24730720,\\\&quot;txId\\\&quot;:4756,\\\&quot;ts_usec\\\&quot;:1684590903517456}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24927256,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24927256,\\\&quot;lsn\\\&quot;:24927256,\\\&quot;txId\\\&quot;:5808,\\\&quot;ts_usec\\\&quot;:1684590940533296}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25109760,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25109760,\\\&quot;lsn\\\&quot;:25109760,\\\&quot;txId\\\&quot;:6765,\\\&quot;ts_usec\\\&quot;:1684590974099949}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 7835 records sent during previous 00:00:04.741, last recorded offset of {server=db_qaookfpaht} partition is {transaction_id=null, lsn_proc=25426664, messageType=INSERT, lsn_commit=25426664, lsn=25426664, txId=8438, ts_usec=1684591035002907}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25292168,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25292168,\\\&quot;lsn\\\&quot;:25292168,\\\&quot;txId\\\&quot;:7718,\\\&quot;ts_usec\\\&quot;:1684591009168356}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25426664,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25426664,\\\&quot;lsn\\\&quot;:25426664,\\\&quot;txId\\\&quot;:8438,\\\&quot;ts_usec\\\&quot;:1684591035002907}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25569000,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25569000,\\\&quot;lsn\\\&quot;:25569000,\\\&quot;txId\\\&quot;:9148,\\\&quot;ts_usec\\\&quot;:1684591060373970}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25586216,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25586216,\\\&quot;lsn\\\&quot;:25586216,\\\&quot;txId\\\&quot;:9199,\\\&quot;ts_usec\\\&quot;:1684591061860151}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):158 Offset file is being written by Debezium. Skipping CDC checkpoint in this loop.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25793264,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25793264,\\\&quot;lsn\\\&quot;:25793264,\\\&quot;txId\\\&quot;:10308,\\\&quot;ts_usec\\\&quot;:1684591100326936}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25964480,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25964480,\\\&quot;lsn\\\&quot;:25964480,\\\&quot;txId\\\&quot;:11160,\\\&quot;ts_usec\\\&quot;:1684591135101788}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26117288,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26117288,\\\&quot;lsn\\\&quot;:26117288,\\\&quot;txId\\\&quot;:11975,\\\&quot;ts_usec\\\&quot;:1684591166567534}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26287840,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26287840,\\\&quot;lsn\\\&quot;:26287840,\\\&quot;txId\\\&quot;:12867,\\\&quot;ts_usec\\\&quot;:1684591198497248}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26310728,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26310728,\\\&quot;lsn\\\&quot;:26310728,\\\&quot;txId\\\&quot;:12991,\\\&quot;ts_usec\\\&quot;:1684591202834079}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26497120,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26497120,\\\&quot;lsn\\\&quot;:26497120,\\\&quot;txId\\\&quot;:13988,\\\&quot;ts_usec\\\&quot;:1684591237894299}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26636720,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26636720,\\\&quot;lsn\\\&quot;:26636720,\\\&quot;txId\\\&quot;:14721,\\\&quot;ts_usec\\\&quot;:1684591265453248}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26804664,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26804664,\\\&quot;lsn\\\&quot;:26804664,\\\&quot;txId\\\&quot;:15618,\\\&quot;ts_usec\\\&quot;:1684591297461127}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26958576,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26958576,\\\&quot;lsn\\\&quot;:26958576,\\\&quot;txId\\\&quot;:16418,\\\&quot;ts_usec\\\&quot;:1684591324343199}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27125800,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27125800,\\\&quot;lsn\\\&quot;:27125800,\\\&quot;txId\\\&quot;:17236,\\\&quot;ts_usec\\\&quot;:1684591351098874}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27261632,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27261632,\\\&quot;lsn\\\&quot;:27261632,\\\&quot;txId\\\&quot;:17899,\\\&quot;ts_usec\\\&quot;:1684591376058315}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27364696,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27364696,\\\&quot;lsn\\\&quot;:27364696,\\\&quot;txId\\\&quot;:18453,\\\&quot;ts_usec\\\&quot;:1684591397272764}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27537976,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27537976,\\\&quot;lsn\\\&quot;:27537976,\\\&quot;txId\\\&quot;:19379,\\\&quot;ts_usec\\\&quot;:1684591430746154}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27716616,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27716616,\\\&quot;lsn\\\&quot;:27716616,\\\&quot;txId\\\&quot;:20334,\\\&quot;ts_usec\\\&quot;:1684591464973620}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27745208,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27745208,\\\&quot;lsn\\\&quot;:27745208,\\\&quot;txId\\\&quot;:20489,\\\&quot;ts_usec\\\&quot;:1684591470517447}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_qaookfpaht\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_qaookfpaht\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27763312,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27763312,\\\&quot;lsn\\\&quot;:27763312,\\\&quot;txId\\\&quot;:20514,\\\&quot;ts_usec\\\&quot;:1684591471348151}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-39 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-39 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: fa7dc89b3475c7f4435902ae44bbd78c4cbcf91fd6267d98b671582abd7d754e&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT6.346108S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-40 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-40 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-41 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-41 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1518425180 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_sbvglnrpdt' AND plugin = 'pgoutput' AND database = 'db_sbvglnrpdt'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.DefaultJdbcDatabase(lambda$unsafeQuery$1):115 closing connection&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@16546957[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-42 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-42 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 505, Xmin Raw Value: 505&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset7273253432439080484/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset7273253432439080484/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@2139247716 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_sbvglnrpdt' AND plugin = 'pgoutput' AND database = 'db_sbvglnrpdt'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset3022825390406569126/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56238/db_sbvglnrpdt with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset3022825390406569126/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset3022825390406569126/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56238&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_sbvglnrpdt' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_sbvglnrpdt'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.012'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_sbvglnrpdt'db='db_sbvglnrpdt', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:05:22.533105Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_sbvglnrpdt\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_sbvglnrpdt\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684591522533105}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-42 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-42 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@494170639 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_sbvglnrpdt' AND plugin = 'pgoutput' AND database = 'db_sbvglnrpdt'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.DefaultJdbcDatabase(lambda$unsafeQuery$1):115 closing connection&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@56ed0511[state={\&quot;[\\\&quot;db_sbvglnrpdt\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_sbvglnrpdt\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684591522533105}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-43 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-43 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 526, Xmin Raw Value: 526&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset11706991026174675852/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset11706991026174675852/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_sbvglnrpdt}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684591522533105}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1305858754 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_sbvglnrpdt' AND plugin = 'pgoutput' AND database = 'db_sbvglnrpdt'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23902672 Saved offset LSN : 23903320&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23907064}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset168730200567274481/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56238/db_sbvglnrpdt with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset168730200567274481/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset168730200567274481/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56238&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_sbvglnrpdt}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684591522533105}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_sbvglnrpdt' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_sbvglnrpdt'db='db_sbvglnrpdt', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:05:22.533105Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_sbvglnrpdt'db='db_sbvglnrpdt', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:05:22.533105Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CBC80}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CBC80}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CBC80}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 21 records sent during previous 00:00:10.698, last recorded offset of {server=db_sbvglnrpdt} partition is {transaction_id=null, lsn_proc=23907064, messageType=INSERT, lsn_commit=23907064, lsn=23907064, txId=525, ts_usec=1684591533741206}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_sbvglnrpdt\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_sbvglnrpdt\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23907064,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23907064,\\\&quot;lsn\\\&quot;:23907064,\\\&quot;txId\\\&quot;:525,\\\&quot;ts_usec\\\&quot;:1684591533741206}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-43 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-43 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1488589205 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_sbvglnrpdt' AND plugin = 'pgoutput' AND database = 'db_sbvglnrpdt'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.DefaultJdbcDatabase(lambda$unsafeQuery$1):115 closing connection&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@69e0d31d[state={\&quot;[\\\&quot;db_sbvglnrpdt\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_sbvglnrpdt\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684591522533105}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-44 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-44 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 527, Xmin Raw Value: 527&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset17848050173115809243/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset17848050173115809243/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_sbvglnrpdt}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684591522533105}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@2125069217 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_sbvglnrpdt' AND plugin = 'pgoutput' AND database = 'db_sbvglnrpdt'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23903320 Saved offset LSN : 23903320&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23907304}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset4896379941286728665/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56238/db_sbvglnrpdt with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset4896379941286728665/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset4896379941286728665/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56238&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_sbvglnrpdt}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684591522533105}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_sbvglnrpdt' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_sbvglnrpdt'db='db_sbvglnrpdt', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:05:22.533105Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_sbvglnrpdt'db='db_sbvglnrpdt', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:05:22.533105Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CBC80}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CBC80}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CBC80}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 22 records sent during previous 00:00:10.699, last recorded offset of {server=db_sbvglnrpdt} partition is {transaction_id=null, lsn_proc=23907304, messageType=INSERT, lsn_commit=23907304, lsn=23907304, txId=526, ts_usec=1684591554811740}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_sbvglnrpdt\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_sbvglnrpdt\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23907304,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23907304,\\\&quot;lsn\\\&quot;:23907304,\\\&quot;txId\\\&quot;:526,\\\&quot;ts_usec\\\&quot;:1684591554811740}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-44 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-44 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1739083136 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_sbvglnrpdt' AND plugin = 'pgoutput' AND database = 'db_sbvglnrpdt'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.DefaultJdbcDatabase(lambda$unsafeQuery$1):115 closing connection&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@21d297a[state={\&quot;[\\\&quot;db_sbvglnrpdt\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_sbvglnrpdt\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23907304,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23907304,\\\&quot;lsn\\\&quot;:23907304,\\\&quot;txId\\\&quot;:526,\\\&quot;ts_usec\\\&quot;:1684591554811740}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-45 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-45 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 528, Xmin Raw Value: 528&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset7129631080819817444/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset7129631080819817444/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_sbvglnrpdt}]: {transaction_id=null, lsn_proc=23907304, messageType=INSERT, lsn_commit=23907304, lsn=23907304, txId=526, ts_usec=1684591554811740}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@2114535546 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_sbvglnrpdt' AND plugin = 'pgoutput' AND database = 'db_sbvglnrpdt'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23903320 Saved offset LSN : 23907304&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23907544}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset12625959273424125003/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56238/db_sbvglnrpdt with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset12625959273424125003/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset12625959273424125003/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56238&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_sbvglnrpdt&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_sbvglnrpdt}]: {transaction_id=null, lsn_proc=23907304, messageType=INSERT, lsn_commit=23907304, lsn=23907304, txId=526, ts_usec=1684591554811740}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_sbvglnrpdt' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CCBE8}, catalogXmin=526]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_sbvglnrpdt'db='db_sbvglnrpdt', lsn=LSN{0/16CCBE8}, txId=526, messageType=INSERT, lastCommitLsn=LSN{0/16CCBE8}, timestamp=2023-05-20T14:05:54.811740Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=LSN{0/16CCBE8}, lastCommitLsn=LSN{0/16CCBE8}, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_sbvglnrpdt'db='db_sbvglnrpdt', lsn=LSN{0/16CCBE8}, txId=526, messageType=INSERT, lastCommitLsn=LSN{0/16CCBE8}, timestamp=2023-05-20T14:05:54.811740Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=LSN{0/16CCBE8}, lastCommitLsn=LSN{0/16CCBE8}, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CCBE8}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'LSN{0/16CCBE8}' and last change LSN 'LSN{0/16CCBE8}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CCBE8}, catalogXmin=526]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CCC20}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):108 Received COMMIT LSN 'LSN{0/16CCCD8}' larger than than last stored commit LSN 'LSN{0/16CCBE8}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):120 Will restart from LSN 'LSN{0/16CCC20}' that is start of the first unprocessed transaction&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CCC20}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_sbvglnrpdt named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_sbvglnrpdt-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CCC20}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 2 records sent during previous 00:00:10.692, last recorded offset of {server=db_sbvglnrpdt} partition is {transaction_id=null, lsn_proc=23907544, messageType=INSERT, lsn_commit=23907544, lsn=23907544, txId=527, ts_usec=1684591575813137}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_sbvglnrpdt\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_sbvglnrpdt\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23907544,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23907544,\\\&quot;lsn\\\&quot;:23907544,\\\&quot;txId\\\&quot;:527,\\\&quot;ts_usec\\\&quot;:1684591575813137}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-45 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-45 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@2033723909 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_sbvglnrpdt' AND plugin = 'pgoutput' AND database = 'db_sbvglnrpdt'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.DefaultJdbcDatabase(lambda$unsafeQuery$1):115 closing connection&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 94d22d3ef63f0d2f644d4249c2f912ce83be434bd12d640f8305cc235a13b3ed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT5.448636S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-46 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-46 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-47 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-47 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(lambda$getCheckOperations$1):138 Attempting to get metadata from the database to see if we can connect.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1981311326 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_azdqfkahxi' AND plugin = 'pgoutput' AND database = 'db_azdqfkahxi'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(check):101 Exception while checking connection: io.airbyte.commons.exceptions.ConfigErrorException: Expected exactly one replication slot but found 0. Please read the docs and add a replication slot to your database.\n\tat io.airbyte.integrations.source.postgres.PostgresSource.lambda$getCheckOperations$5(PostgresSource.java:318) ~[main/:?]\n\tat io.airbyte.integrations.source.relationaldb.AbstractDbSource.check(AbstractDbSource.java:87) ~[io.airbyte.airbyte-integrations.connectors-source-relational-db-0.44.4.jar:?]\n\tat io.airbyte.integrations.source.postgres.PostgresSource.check(PostgresSource.java:527) ~[main/:?]\n\tat io.airbyte.integrations.source.postgres.CdcPostgresSourceTest.testCheckWithoutReplicationSlot(CdcPostgresSourceTest.java:227) ~[test/:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]\n\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]\n\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727) ~[junit-platform-commons-1.9.1.jar:1.9.1]\n\tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:86) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat java.util.ArrayList.forEach(ArrayList.java:1511) ~[?:?]\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat java.util.ArrayList.forEach(ArrayList.java:1511) ~[?:?]\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:62) ~[?:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]\n\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36) ~[?:?]\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24) ~[?:?]\n\tat org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33) ~[?:?]\n\tat org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94) ~[?:?]\n\tat jdk.proxy2.$Proxy5.stop(Unknown Source) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60) ~[?:?]\n\tat org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56) ~[?:?]\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:113) ~[?:?]\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:65) ~[?:?]\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69) ~[gradle-worker.jar:?]\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74) ~[gradle-worker.jar:?]\n&quot;,&quot;stack_trace&quot;:&quot;io.airbyte.commons.exceptions.ConfigErrorException: Expected exactly one replication slot but found 0. Please read the docs and add a replication slot to your database.\n\tat io.airbyte.integrations.source.postgres.PostgresSource.lambda$getCheckOperations$5(PostgresSource.java:318)\n\tat io.airbyte.integrations.source.relationaldb.AbstractDbSource.check(AbstractDbSource.java:87)\n\tat io.airbyte.integrations.source.postgres.PostgresSource.check(PostgresSource.java:527)\n\tat io.airbyte.integrations.source.postgres.CdcPostgresSourceTest.testCheckWithoutReplicationSlot(CdcPostgresSourceTest.java:227)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727)\n\tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:86)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)\n\tat org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)\n\tat org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75)\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:62)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)\n\tat org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)\n\tat jdk.proxy2/jdk.proxy2.$Proxy5.stop(Unknown Source)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60)\n\tat org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56)\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:113)\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:65)\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69)\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74)\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-47 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-47 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 7dfdd0e18da435c31fd5ebda210289f968c459ff84fbab7cef289700587eff56&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT5.099982S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-48 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-48 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-49 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-49 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(lambda$getCheckOperations$1):138 Attempting to get metadata from the database to see if we can connect.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@235208892 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_itezwqugvo' AND plugin = 'pgoutput' AND database = 'db_itezwqugvo'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getCheckOperations$6):328 Attempting to find the publication using the query: HikariProxyPreparedStatement@895698515 wrapping SELECT * FROM pg_publication WHERE pubname = 'publication'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(check):101 Exception while checking connection: io.airbyte.commons.exceptions.ConfigErrorException: User 'airbyte_test' does not have enough privileges for CDC replication. Please read the docs and add required privileges.\n\tat io.airbyte.integrations.debezium.internals.postgres.PostgresReplicationConnection.createConnection(PostgresReplicationConnection.java:52) ~[io.airbyte.airbyte-integrations.bases-debezium-0.44.4.jar:?]\n\tat io.airbyte.integrations.source.postgres.PostgresSource.lambda$getCheckOperations$9(PostgresSource.java:353) ~[main/:?]\n\tat io.airbyte.integrations.source.relationaldb.AbstractDbSource.check(AbstractDbSource.java:87) ~[io.airbyte.airbyte-integrations.connectors-source-relational-db-0.44.4.jar:?]\n\tat io.airbyte.integrations.source.postgres.PostgresSource.check(PostgresSource.java:527) ~[main/:?]\n\tat io.airbyte.integrations.source.postgres.CdcPostgresSourceTest.testCheckWithoutReplicationPermission(CdcPostgresSourceTest.java:208) ~[test/:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]\n\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]\n\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727) ~[junit-platform-commons-1.9.1.jar:1.9.1]\n\tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:86) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat java.util.ArrayList.forEach(ArrayList.java:1511) ~[?:?]\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat java.util.ArrayList.forEach(ArrayList.java:1511) ~[?:?]\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) ~[junit-platform-engine-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53) ~[junit-platform-launcher-1.9.1.jar:1.9.1]\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:62) ~[?:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]\n\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36) ~[?:?]\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24) ~[?:?]\n\tat org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33) ~[?:?]\n\tat org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94) ~[?:?]\n\tat jdk.proxy2.$Proxy5.stop(Unknown Source) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100) ~[?:?]\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60) ~[?:?]\n\tat org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56) ~[?:?]\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:113) ~[?:?]\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:65) ~[?:?]\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69) ~[gradle-worker.jar:?]\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74) ~[gradle-worker.jar:?]\n&quot;,&quot;stack_trace&quot;:&quot;io.airbyte.commons.exceptions.ConfigErrorException: User 'airbyte_test' does not have enough privileges for CDC replication. Please read the docs and add required privileges.\n\tat io.airbyte.integrations.debezium.internals.postgres.PostgresReplicationConnection.createConnection(PostgresReplicationConnection.java:52)\n\tat io.airbyte.integrations.source.postgres.PostgresSource.lambda$getCheckOperations$9(PostgresSource.java:353)\n\tat io.airbyte.integrations.source.relationaldb.AbstractDbSource.check(AbstractDbSource.java:87)\n\tat io.airbyte.integrations.source.postgres.PostgresSource.check(PostgresSource.java:527)\n\tat io.airbyte.integrations.source.postgres.CdcPostgresSourceTest.testCheckWithoutReplicationPermission(CdcPostgresSourceTest.java:208)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727)\n\tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:86)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)\n\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)\n\tat org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)\n\tat org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75)\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:62)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)\n\tat org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)\n\tat jdk.proxy2/jdk.proxy2.$Proxy5.stop(Unknown Source)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60)\n\tat org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56)\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:113)\n\tat org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:65)\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69)\n\tat worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74)\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-49 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-49 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 3405e54a120aba9359f0a8d081af5d6fcc171b85c7e5e6c0ad6fb55a4a82930d&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT5.306857S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-50 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-50 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-51 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-51 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(lambda$getCheckOperations$1):138 Attempting to get metadata from the database to see if we can connect.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1489706872 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_ptmfgewfts' AND plugin = 'pgoutput' AND database = 'db_ptmfgewfts'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getCheckOperations$6):328 Attempting to find the publication using the query: HikariProxyPreparedStatement@987300143 wrapping SELECT * FROM pg_publication WHERE pubname = 'publication'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-51 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-51 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: d6ad6f6bf286b43d8d9c9e5a718cc00789c326f7c6bc4310f95cdba925e90c83&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT5.200382S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-52 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-52 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@65ff5e07[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-53 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-53 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 505, Xmin Raw Value: 505&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset9009617457374567916/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset9009617457374567916/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1625390205 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_tiuxmgttks' AND plugin = 'pgoutput' AND database = 'db_tiuxmgttks'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset9779462897141951356/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56302/db_tiuxmgttks with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset9779462897141951356/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_tiuxmgttks&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_tiuxmgttks&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset9779462897141951356/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_tiuxmgttks&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56302&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_tiuxmgttks&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_tiuxmgttks' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_tiuxmgttks named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_tiuxmgttks-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_tiuxmgttks'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.009'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_tiuxmgttks'db='db_tiuxmgttks', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:07:10.924585Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_tiuxmgttks named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_tiuxmgttks-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_tiuxmgttks named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_tiuxmgttks-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684591630924585}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-53 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-53 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@643afff3[state={\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684591630924585}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-54 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-54 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 20514, Xmin Raw Value: 20514&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset9408983908299847552/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset9408983908299847552/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_tiuxmgttks}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684591630924585}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@480156667 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_tiuxmgttks' AND plugin = 'pgoutput' AND database = 'db_tiuxmgttks'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23902672 Saved offset LSN : 23903320&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):44 Creating a replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresReplicationConnection(createConnection):47 Validating replication connection.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=27721984}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset15778771181153547157/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56302/db_tiuxmgttks with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset15778771181153547157/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1070 Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_tiuxmgttks&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_tiuxmgttks&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset15778771181153547157/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    flush.lsn.source = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_tiuxmgttks&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56302&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_tiuxmgttks&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_tiuxmgttks}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684591630924585}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_tiuxmgttks' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_tiuxmgttks'db='db_tiuxmgttks', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:07:10.924585Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_tiuxmgttks named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_tiuxmgttks-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_tiuxmgttks'db='db_tiuxmgttks', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:07:10.924585Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_tiuxmgttks named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_tiuxmgttks-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CBC80}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CBC80}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_tiuxmgttks named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_tiuxmgttks-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CBC80}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23936392,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23936392,\\\&quot;lsn\\\&quot;:23936392,\\\&quot;txId\\\&quot;:685,\\\&quot;ts_usec\\\&quot;:1684591646226405}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24143712,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24143712,\\\&quot;lsn\\\&quot;:24143712,\\\&quot;txId\\\&quot;:1795,\\\&quot;ts_usec\\\&quot;:1684591676884991}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24269352,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24269352,\\\&quot;lsn\\\&quot;:24269352,\\\&quot;txId\\\&quot;:2467,\\\&quot;ts_usec\\\&quot;:1684591696118563}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24454192,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24454192,\\\&quot;lsn\\\&quot;:24454192,\\\&quot;txId\\\&quot;:3460,\\\&quot;ts_usec\\\&quot;:1684591725274638}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24696320,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24696320,\\\&quot;lsn\\\&quot;:24696320,\\\&quot;txId\\\&quot;:4755,\\\&quot;ts_usec\\\&quot;:1684591760018261}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:24938480,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:24938480,\\\&quot;lsn\\\&quot;:24938480,\\\&quot;txId\\\&quot;:5866,\\\&quot;ts_usec\\\&quot;:1684591791862623}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25145712,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25145712,\\\&quot;lsn\\\&quot;:25145712,\\\&quot;txId\\\&quot;:6976,\\\&quot;ts_usec\\\&quot;:1684591823514927}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25358376,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25358376,\\\&quot;lsn\\\&quot;:25358376,\\\&quot;txId\\\&quot;:8087,\\\&quot;ts_usec\\\&quot;:1684591855944962}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 8690 records sent during previous 00:00:05.22, last recorded offset of {server=db_tiuxmgttks} partition is {transaction_id=null, lsn_proc=25565608, messageType=INSERT, lsn_commit=25565608, lsn=25565608, txId=9197, ts_usec=1684591887243866}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25397768,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25397768,\\\&quot;lsn\\\&quot;:25397768,\\\&quot;txId\\\&quot;:8296,\\\&quot;ts_usec\\\&quot;:1684591861909592}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25565608,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25565608,\\\&quot;lsn\\\&quot;:25565608,\\\&quot;txId\\\&quot;:9197,\\\&quot;ts_usec\\\&quot;:1684591887243866}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25775992,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25775992,\\\&quot;lsn\\\&quot;:25775992,\\\&quot;txId\\\&quot;:10308,\\\&quot;ts_usec\\\&quot;:1684591918646759}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:25958456,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:25958456,\\\&quot;lsn\\\&quot;:25958456,\\\&quot;txId\\\&quot;:11241,\\\&quot;ts_usec\\\&quot;:1684591945359021}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26216544,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26216544,\\\&quot;lsn\\\&quot;:26216544,\\\&quot;txId\\\&quot;:12529,\\\&quot;ts_usec\\\&quot;:1684591982624101}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26426728,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26426728,\\\&quot;lsn\\\&quot;:26426728,\\\&quot;txId\\\&quot;:13640,\\\&quot;ts_usec\\\&quot;:1684592014574784}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26633984,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26633984,\\\&quot;lsn\\\&quot;:26633984,\\\&quot;txId\\\&quot;:14750,\\\&quot;ts_usec\\\&quot;:1684592046847293}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:26847504,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:26847504,\\\&quot;lsn\\\&quot;:26847504,\\\&quot;txId\\\&quot;:15861,\\\&quot;ts_usec\\\&quot;:1684592080449876}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27054736,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27054736,\\\&quot;lsn\\\&quot;:27054736,\\\&quot;txId\\\&quot;:16971,\\\&quot;ts_usec\\\&quot;:1684592114316508}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27226288,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27226288,\\\&quot;lsn\\\&quot;:27226288,\\\&quot;txId\\\&quot;:17873,\\\&quot;ts_usec\\\&quot;:1684592140734076}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27264864,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27264864,\\\&quot;lsn\\\&quot;:27264864,\\\&quot;txId\\\&quot;:18082,\\\&quot;ts_usec\\\&quot;:1684592146800233}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27472096,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27472096,\\\&quot;lsn\\\&quot;:27472096,\\\&quot;txId\\\&quot;:19192,\\\&quot;ts_usec\\\&quot;:1684592178538904}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumStateDecoratingIterator(computeNext):135 Sending CDC checkpoint state message.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27682224,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27682224,\\\&quot;lsn\\\&quot;:27682224,\\\&quot;txId\\\&quot;:20303,\\\&quot;ts_usec\\\&quot;:1684592210853375}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 11312 records sent during previous 00:00:15.751, last recorded offset of {server=db_tiuxmgttks} partition is {transaction_id=null, lsn_proc=27721984, messageType=INSERT, lsn_commit=27721984, lsn=27721984, txId=20513, ts_usec=1684592216869852}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_tiuxmgttks\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_tiuxmgttks\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:27721984,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:27721984,\\\&quot;lsn\\\&quot;:27721984,\\\&quot;txId\\\&quot;:20513,\\\&quot;ts_usec\\\&quot;:1684592216869852}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-54 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-54 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: 62d47621897c42922728edc10cad385f68110290ddb5ab36d8ef3874aef65d75&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT5.200333S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-55 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-55 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.CursorManager(createCursorInfoForStream):182 No cursor field set in catalog but not present in state. Stream: models_schema_models, New Cursor Field: null. Resetting cursor value&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@65209f9b[state=&lt;null&gt;,additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-56 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-56 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 505, Xmin Raw Value: 505&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset340217383806166963/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset340217383806166963/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):206 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@694886538 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_kqoclebyqc' AND plugin = 'pgoutput' AND database = 'db_kqoclebyqc'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset1427182686825855120/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56387/db_kqoclebyqc with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset1427182686825855120/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset1427182686825855120/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56387&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_kqoclebyqc' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_kqoclebyqc named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_kqoclebyqc-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CBC58}' from transaction '505'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_kqoclebyqc'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 6 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.01'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_kqoclebyqc'db='db_kqoclebyqc', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:17:36.448742Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CB9D0}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(validateSlotIsInExpectedState):364 Seeking to LSN{0/16CBC58} on the replication slot with command SELECT pg_replication_slot_advance('debezium_slot_db_kqoclebyqc', '0/16CBC58')&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_kqoclebyqc named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_kqoclebyqc-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(validateSlotIsInExpectedState):364 Seeking to LSN{0/16CBC58} on the replication slot with command SELECT pg_replication_slot_advance('debezium_slot_db_kqoclebyqc', '0/16CBC58')&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_kqoclebyqc named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_kqoclebyqc-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_kqoclebyqc\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_kqoclebyqc\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684592256448742}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-56 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-56 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@b66d50c[state={\&quot;[\\\&quot;db_kqoclebyqc\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_kqoclebyqc\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684592256448742}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-57 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-57 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 526, Xmin Raw Value: 526&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset9655327550889020020/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset9655327550889020020/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_kqoclebyqc}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684592256448742}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1434727271 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_kqoclebyqc' AND plugin = 'pgoutput' AND database = 'db_kqoclebyqc'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23903320 Saved offset LSN : 23903320&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23907064}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset5911677479667156541/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56387/db_kqoclebyqc with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset5911677479667156541/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset5911677479667156541/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56387&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):370 Found previous partition offset PostgresPartition [sourcePartition={server=db_kqoclebyqc}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684592256448742}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_kqoclebyqc' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):127 Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_kqoclebyqc'db='db_kqoclebyqc', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:17:36.448742Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_kqoclebyqc named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_kqoclebyqc-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 Previous snapshot has completed successfully, streaming logical changes from last known position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):68 According to the connector configuration no snapshot will be executed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_kqoclebyqc'db='db_kqoclebyqc', lsn=LSN{0/16CBC58}, txId=505, timestamp=2023-05-20T14:17:36.448742Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CBC58}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CBC58}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(validateSlotIsInExpectedState):364 Seeking to LSN{0/16CBC58} on the replication slot with command SELECT pg_replication_slot_advance('debezium_slot_db_kqoclebyqc', '0/16CBC58')&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_kqoclebyqc named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_kqoclebyqc-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(resumeFromLsn):71 First LSN 'LSN{0/16CBC80}' received&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'LSN{0/16CBC80}' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(validateSlotIsInExpectedState):364 Seeking to LSN{0/16CBC58} on the replication slot with command SELECT pg_replication_slot_advance('debezium_slot_db_kqoclebyqc', '0/16CBC58')&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_kqoclebyqc named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_kqoclebyqc-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(skipMessage):152 Message with LSN 'LSN{0/16CBC80}' arrived, switching off the filtering&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(logStatistics):195 21 records sent during previous 00:00:10.235, last recorded offset of {server=db_kqoclebyqc} partition is {transaction_id=null, lsn_proc=23907064, messageType=INSERT, lsn_commit=23907064, lsn=23907064, txId=525, ts_usec=1684592267398766}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Heartbeat indicates sync is done&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_kqoclebyqc\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_kqoclebyqc\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn_proc\\\&quot;:23907064,\\\&quot;messageType\\\&quot;:\\\&quot;INSERT\\\&quot;,\\\&quot;lsn_commit\\\&quot;:23907064,\\\&quot;lsn\\\&quot;:23907064,\\\&quot;txId\\\&quot;:525,\\\&quot;ts_usec\\\&quot;:1684592267398766}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-57 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-57 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.s.StateManagerFactory(createStateManager):51 Global state manager selected to manage state object with type GLOBAL.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.CdcStateManager(&lt;init&gt;):29 Initialized CDC state with: io.airbyte.integrations.source.relationaldb.models.CdcState@221ffed[state={\&quot;[\\\&quot;db_kqoclebyqc\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_kqoclebyqc\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23903320,\\\&quot;txId\\\&quot;:505,\\\&quot;ts_usec\\\&quot;:1684592256448742}\&quot;},additionalProperties={}]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-58 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-58 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcCatalogHelper(getPublicizedTables):119 For CDC, only tables in publication publication will be included in the sync: [models_schema.models, models_schema_random.models_random]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(logPreSyncDebugData):450 Data source product recognized as PostgreSQL:13.11&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):221 Discovering indexes for schema \&quot;models_schema\&quot;, table \&quot;models\&quot;&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(logPreSyncDebugData):223 Index name: models_pkey, Column: id, Unique: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresQueryUtils(logXminStatus):77 Xmin Status : {Number of wraparounds: 0, Xmin Transaction Value: 527, Xmin Raw Value: 527&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.j.AbstractJdbcSource(discoverInternal):166 Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(isCdc):53 using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):111 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(getIncrementalIterators):369 First record waiting time: 30 seconds&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 StandaloneConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset18191171171920233879/offset.dat\n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset18191171171920233879/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(extractLsn):201 Found previous partition offset PostgresPartition [sourcePartition={server=db_kqoclebyqc}]: {transaction_id=null, lsn=23903320, txId=505, ts_usec=1684592256448742}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(parseSavedOffset):181 Closing offsetStorageReader and fileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):296 Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@1048224457 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium_slot_db_kqoclebyqc' AND plugin = 'pgoutput' AND database = 'db_kqoclebyqc'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 Set initial fetch size: 10 rows&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):62 Replication slot confirmed_flush_lsn : 23907064 Saved offset LSN : 23903320&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN i.a.i.s.p.PostgresSource(getIncrementalIterators):397 Saved offset is before Replication slot's confirmed_flush_lsn, Airbyte will trigger sync from scratch&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23907304}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):61 Should flush after sync: false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.AirbyteDebeziumHandler(getIncrementalIterators):95 Using CDC: true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 EmbeddedConfig values: \n\taccess.control.allow.methods = \n\taccess.control.allow.origin = \n\tadmin.listeners = null\n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [localhost:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tconfig.providers = []\n\tconnector.client.config.override.policy = All\n\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n\tlisteners = [http://:8083]\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\toffset.flush.interval.ms = 1000\n\toffset.flush.timeout.ms = 5000\n\toffset.storage.file.filename = /tmp/cdc-state-offset2245802673672260192/offset.dat\n\toffset.storage.partitions = null\n\toffset.storage.replication.factor = null\n\toffset.storage.topic = \n\tplugin.path = null\n\tresponse.http.headers.config = \n\trest.advertised.host.name = null\n\trest.advertised.listener = null\n\trest.advertised.port = null\n\trest.extension.classes = []\n\tssl.cipher.suites = null\n\tssl.client.auth = none\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttask.shutdown.graceful.timeout.ms = 5000\n\ttopic.creation.enable = true\n\ttopic.tracking.allow.reset = true\n\ttopic.tracking.enable = true\n\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;WARN&quot;,&quot;message&quot;:&quot;WARN o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):379 Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = key\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.c.AbstractConfig(logAll):376 JsonConverterConfig values: \n\tconverter.type = value\n\tdecimal.format = BASE64\n\tschemas.cache.size = 1000\n\tschemas.enable = false\n&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnector(testConnection):154 Successfully tested connection for jdbc:postgresql://localhost:56387/db_kqoclebyqc with user 'test'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(start):58 Starting FileOffsetBackingStore with file /tmp/cdc-state-offset2245802673672260192/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(start):124 Starting PostgresConnectorTask with configuration:&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    connector.class = io.debezium.connector.postgresql.PostgresConnector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.queue.size = 8192&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    slot.name = debezium_slot_db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.name = publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    topic.prefix = db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage.file.filename = /tmp/cdc-state-offset2245802673672260192/offset.dat&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    decimal.handling.mode = string&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    converters = datetime&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.initial.ms = 299&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    datetime.type = io.airbyte.integrations.debezium.internals.postgres.PostgresConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter = org.apache.kafka.connect.json.JsonConverter&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    publication.autocreate.mode = disabled&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.user = test&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.dbname = db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.retry.delay.max.ms = 300&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.timeout.ms = 5000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    heartbeat.interval.ms = 10000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    column.include.list = \\Qmodels_schema.models\\E\\.(\\Qmodel\\E|\\Qid\\E|\\Qmake_id\\E)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    plugin.name = pgoutput&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.port = 56387&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    offset.flush.interval.ms = 1000&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    key.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    include.unknown.datatypes = true&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    errors.max.retries = 10&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.hostname = localhost&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    database.password = ********&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    value.converter.schemas.enable = false&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    name = db_kqoclebyqc&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    max.batch.size = 2048&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    table.include.list = \\Qmodels_schema.models\\E&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(lambda$start$0):126    snapshot.mode = initial&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):243 Attempting to start task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.CommonConnectorConfig(getTopicNamingStrategy):849 Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(getPreviousOffsets):375 No previous offsets found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):113 user 'test' connected to database 'db_kqoclebyqc' on PostgreSQL 13.11 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:\n\trole 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'test' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]\n\trole 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]\n\trole 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CCAF8}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresConnectorTask(start):122 No previous offset found&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_kqoclebyqc named = change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_kqoclebyqc-change-event-source-coordinator&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(startIfNeededAndPossible):245 Successfully started task&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):103 Metrics registered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(lambda$start$0):106 Context created&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.s.InitialSnapshotter(shouldSnapshot):34 Taking initial snapshot for new datasource&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):65 According to the connector configuration data will be snapshotted&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):110 Snapshot step 1 - Preparing&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):119 Snapshot step 2 - Determining captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema.models to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(determineCapturedTables):267 Adding table models_schema_random.models_random to the list of capture schema tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):126 Snapshot step 3 - Locking captured tables [models_schema.models]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):132 Snapshot step 4 - Determining snapshot offset&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):233 Creating initial offset context&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresOffsetContext(initialContext):236 Read xlogStart at 'LSN{0/16CCBE8}' from transaction '527'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(updateOffsetForSnapshot):147 Read xlogStart at 'LSN{0/16CCBE8}' from transaction '527'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):135 Snapshot step 5 - Reading structure of captured tables&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSnapshotChangeEventSource(readTableStructure):193 Reading structure of schema 'models_schema' of catalog 'db_kqoclebyqc'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):139 Snapshot step 5.a - Creating connection pool&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createConnectionPool):213 Created connection pool with 1 threads&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):144 Snapshot step 6 - Persisting schema history&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doExecute):156 Snapshot step 7 - Snapshotting data&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):390 Creating snapshot worker pool with 1 worker thread(s)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(createDataEvents):399 For table 'models_schema.models' using select statement: 'SELECT \&quot;id\&quot;, \&quot;make_id\&quot;, \&quot;model\&quot; FROM \&quot;models_schema\&quot;.\&quot;models\&quot;'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):513 Exporting data from table 'models_schema.models' (1 of 1 tables)&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.r.RelationalSnapshotChangeEventSource(doCreateDataEventsForTable):559 \t Finished exporting 27 records for table 'models_schema.models' (1 of 1 tables); total duration '00:00:00.011'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):88 Snapshot - Final stage&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.s.AbstractSnapshotChangeEventSource(execute):92 Snapshot completed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(doSnapshot):156 Snapshot ended with SnapshotResult [status=COMPLETED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='db_kqoclebyqc'db='db_kqoclebyqc', lsn=LSN{0/16CCBE8}, txId=527, timestamp=2023-05-20T14:18:08.198648Z, snapshot=FALSE, schema=models_schema, table=models], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'true'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):173 Starting streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(execute):136 Retrieved latest position from stored offset 'LSN{0/16CCBE8}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.WalPositionLocator(&lt;init&gt;):48 Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/16CCBE8}'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):264 Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/16CCAF8}, catalogXmin=504]&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(validateSlotIsInExpectedState):364 Seeking to LSN{0/16CCBE8} on the replication slot with command SELECT pg_replication_slot_advance('debezium_slot_db_kqoclebyqc', '0/16CCBE8')&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(reachedTargetPosition):61 Signalling close because Snapshot is complete&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordIterator(requestClose):208 Closing: Change event reached target position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1146 Stopping the embedded engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(stop):1153 Waiting for PT5M for connector to stop&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_kqoclebyqc named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_kqoclebyqc-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 REPLICA IDENTITY for 'models_schema.models' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):327 Searching for WAL resume position&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.e.EmbeddedEngine(run):944 Stopping the task and engine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.c.BaseSourceTask(stop):278 Stopping down connector&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):348 WAL resume position 'null' discovered&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(initPublication):147 Initializing PgOutput logical decoder publication&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.c.PostgresReplicationConnection(validateSlotIsInExpectedState):364 Seeking to LSN{0/16CCBE8} on the replication slot with command SELECT pg_replication_slot_advance('debezium_slot_db_kqoclebyqc', '0/16CCBE8')&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads(threadFactory):270 Requested thread factory for connector PostgresConnector, id = db_kqoclebyqc named = keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.u.Threads$3(newThread):287 Creating thread debezium-postgresconnector-db_kqoclebyqc-keep-alive&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.c.p.PostgresStreamingChangeEventSource(processMessages):211 Processing messages&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.j.JdbcConnection(lambda$doClose$4):947 Connection gracefully closed&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamEvents):175 Finished streaming&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.d.p.ChangeEventSourceCoordinator(streamingConnected):240 Connected metrics set to 'false'&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.a.k.c.s.FileOffsetBackingStore(stop):66 Stopped FileOffsetBackingStore&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):73 Debezium engine shutdown.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.DebeziumRecordPublisher(lambda$start$1):74 Connector 'io.debezium.connector.postgresql.PostgresConnector' completed normally.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.p.PostgresCdcStateHandler(saveState):37 debezium state: {\&quot;[\\\&quot;db_kqoclebyqc\\\&quot;,{\\\&quot;server\\\&quot;:\\\&quot;db_kqoclebyqc\\\&quot;}]\&quot;:\&quot;{\\\&quot;transaction_id\\\&quot;:null,\\\&quot;lsn\\\&quot;:23907304,\\\&quot;txId\\\&quot;:527,\\\&quot;ts_usec\\\&quot;:1684592288198648}\&quot;}&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):173 Closing database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):350 HikariPool-58 - Shutdown initiated...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(close):352 HikariPool-58 - Shutdown completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.s.r.AbstractDbSource(lambda$read$1):175 Closed database connection pool.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):376 Creating container for image: debezium/postgres:13-alpine&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):440 Container debezium/postgres:13-alpine is starting: c15235caa774e927d93b8e1519ea452f87340957ebce45e6550880c4edde04e1&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO o.t.c.GenericContainer(tryStart):520 Container debezium/postgres:13-alpine started in PT9.569683S&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-59 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-59 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):80 HikariPool-60 - Starting...&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO c.z.h.HikariDataSource(&lt;init&gt;):82 HikariPool-60 - Start completed.&quot;}}
{&quot;type&quot;:&quot;LOG&quot;,&quot;log&quot;:{&quot;level&quot;:&quot;INFO&quot;,&quot;message&quot;:&quot;INFO i.a.i.d.i.p.PostgresCdcTargetPosition(targetPosition):49 identified target lsn: PgLsn{lsn=23903320}&quot;}}
</pre>
</span>
</div>
</div>
<div id="footer">
<p>
<div>
<label class="hidden" id="label-for-line-wrapping-toggle" for="line-wrapping-toggle">Wrap lines
<input id="line-wrapping-toggle" type="checkbox" autocomplete="off"/>
</label>
</div>Generated by 
<a href="http://www.gradle.org">Gradle 7.6</a> at May 20, 2023, 10:18:40 AM</p>
</div>
</div>
</body>
</html>
